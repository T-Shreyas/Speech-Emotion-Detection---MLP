{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKNo9RTBj1hA"
   },
   "source": [
    "#Speech Emotion Recognition with MLP Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrH14Ttlo2EL"
   },
   "source": [
    "# Install following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "spdyH1iXo5lB",
    "outputId": "82aad428-c6f8-4a79-e26e-6023ba37673e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in d:\\anaconda\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: soundfile in d:\\anaconda\\lib\\site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (1.19.5)\n",
      "Requirement already satisfied: sklearn in d:\\anaconda\\lib\\site-packages (0.0)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.11.tar.gz (37 kB)\n",
      "Requirement already satisfied: pooch>=1.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in d:\\anaconda\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numba>=0.43.0 in d:\\anaconda\\lib\\site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in d:\\anaconda\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in d:\\anaconda\\lib\\site-packages (from librosa) (5.0.6)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in d:\\anaconda\\lib\\site-packages (from librosa) (0.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from librosa) (20.9)\n",
      "Requirement already satisfied: joblib>=0.14 in d:\\anaconda\\lib\\site-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.6.2)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\anaconda\\lib\\site-packages (from soundfile) (1.14.5)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in d:\\anaconda\\lib\\site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from numba>=0.43.0->librosa) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: appdirs in d:\\anaconda\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from pooch>=1.0->librosa) (2.25.1)\n",
      "Requirement already satisfied: six>=1.3 in d:\\anaconda\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Building wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (setup.py): started\n",
      "  Building wheel for pyaudio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyaudio\n",
      "Failed to build pyaudio\n",
      "Installing collected packages: pyaudio\n",
      "    Running setup.py install for pyaudio: started\n",
      "    Running setup.py install for pyaudio: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'D:\\Anaconda\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\pip-install-9xit0o08\\\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\pip-install-9xit0o08\\\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Dell\\AppData\\Local\\Temp\\pip-wheel-7bxrzaf9'\n",
      "       cwd: C:\\Users\\Dell\\AppData\\Local\\Temp\\pip-install-9xit0o08\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\n",
      "  Complete output (17 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  copying src\\pyaudio.py -> build\\lib.win-amd64-3.8\n",
      "  running build_ext\n",
      "  building '_portaudio' extension\n",
      "  creating build\\temp.win-amd64-3.8\n",
      "  creating build\\temp.win-amd64-3.8\\Release\n",
      "  creating build\\temp.win-amd64-3.8\\Release\\src\n",
      "  F:\\visual\\VC\\Tools\\MSVC\\14.30.30705\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -DMS_WIN64=1 -ID:\\Anaconda\\include -ID:\\Anaconda\\include -IF:\\visual\\VC\\Tools\\MSVC\\14.30.30705\\ATLMFC\\include -IF:\\visual\\VC\\Tools\\MSVC\\14.30.30705\\include \"-IF:\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcsrc/_portaudiomodule.c /Fobuild\\temp.win-amd64-3.8\\Release\\src/_portaudiomodule.obj\n",
      "  _portaudiomodule.c\n",
      "  D:\\Anaconda\\include\\pyconfig.h(117): warning C4005: 'MS_WIN64': macro redefinition\n",
      "  src/_portaudiomodule.c: note: see previous definition of 'MS_WIN64'\n",
      "  src/_portaudiomodule.c(29): fatal error C1083: Cannot open include file: 'portaudio.h': No such file or directory\n",
      "  error: command 'F:\\\\visual\\\\VC\\\\Tools\\\\MSVC\\\\14.30.30705\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit status 2\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyaudio\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\Anaconda\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\pip-install-9xit0o08\\\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\pip-install-9xit0o08\\\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Dell\\AppData\\Local\\Temp\\pip-record-cc45qmod\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Anaconda\\Include\\pyaudio'\n",
      "         cwd: C:\\Users\\Dell\\AppData\\Local\\Temp\\pip-install-9xit0o08\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\n",
      "    Complete output (17 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    copying src\\pyaudio.py -> build\\lib.win-amd64-3.8\n",
      "    running build_ext\n",
      "    building '_portaudio' extension\n",
      "    creating build\\temp.win-amd64-3.8\n",
      "    creating build\\temp.win-amd64-3.8\\Release\n",
      "    creating build\\temp.win-amd64-3.8\\Release\\src\n",
      "    F:\\visual\\VC\\Tools\\MSVC\\14.30.30705\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -DMS_WIN64=1 -ID:\\Anaconda\\include -ID:\\Anaconda\\include -IF:\\visual\\VC\\Tools\\MSVC\\14.30.30705\\ATLMFC\\include -IF:\\visual\\VC\\Tools\\MSVC\\14.30.30705\\include \"-IF:\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IF:\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcsrc/_portaudiomodule.c /Fobuild\\temp.win-amd64-3.8\\Release\\src/_portaudiomodule.obj\n",
      "    _portaudiomodule.c\n",
      "    D:\\Anaconda\\include\\pyconfig.h(117): warning C4005: 'MS_WIN64': macro redefinition\n",
      "    src/_portaudiomodule.c: note: see previous definition of 'MS_WIN64'\n",
      "    src/_portaudiomodule.c(29): fatal error C1083: Cannot open include file: 'portaudio.h': No such file or directory\n",
      "    error: command 'F:\\\\visual\\\\VC\\\\Tools\\\\MSVC\\\\14.30.30705\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit status 2\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'D:\\Anaconda\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\pip-install-9xit0o08\\\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\pip-install-9xit0o08\\\\pyaudio_0f2ad265d5a04a05a1695d621ef61d0f\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Dell\\AppData\\Local\\Temp\\pip-record-cc45qmod\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Anaconda\\Include\\pyaudio' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa soundfile numpy sklearn pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "JdmYeo1-fXtz",
    "outputId": "b5202521-fdac-438a-8596-8bd2fe312e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in d:\\anaconda\\lib\\site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\anaconda\\lib\\site-packages (from soundfile) (1.14.5)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tqlY-_LUpD3l"
   },
   "source": [
    "# Make the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fyYSbcJjy7i"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QufSKr1ksJc"
   },
   "source": [
    "Define a function extract_feature to extract the mfcc, chroma, and mel features from a sound file. This function takes 4 parameters- the file name and three Boolean parameters for the three features:\n",
    "\n",
    "* mfcc: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound\n",
    "* chroma: Pertains to the 12 different pitch classes\n",
    "* mel: Mel Spectrogram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwB6D_vLpOoR"
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
    "    if chroma:\n",
    "        stft=np.abs(librosa.stft(X))\n",
    "    result=np.array([])\n",
    "    if mfcc:\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xKzPyVcjvyT"
   },
   "source": [
    "Now, let’s define a dictionary to hold numbers and the emotions available in the RAVDESS & TESS dataset, and a list to hold all 8 emotions- neutral,calm,happy,sad,angry,fearful,disgust,surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgwcKBQzpdgM"
   },
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS & TESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "# Emotions to observe\n",
    "observed_emotions=['neutral','calm','happy','sad','angry','fearful', 'disgust','surprised']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VjDiYuC3G-D"
   },
   "source": [
    "# Load the data and extract features for each sound file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2axyBFDqI1A"
   },
   "outputs": [],
   "source": [
    "#Load the data and extract features for each sound file\n",
    "def load_data(test_size = 0.2):\n",
    "  x, y = [], []\n",
    "  for folder in glob.glob('C:/Users/Dell/Desktop/set/Actor_*'):\n",
    "    print(folder)\n",
    "    for file in glob.glob(folder + '/*.wav'):\n",
    "      file_name = os.path.basename(file)\n",
    "      emotion = emotions[file_name.split('-')[2]]\n",
    "      if emotion not in observed_emotions:\n",
    "        continue\n",
    "      feature = extract_feature(file, mfcc = True, chroma = True, mel = True)\n",
    "      x.append(feature)\n",
    "      y.append(emotion)\n",
    "  return train_test_split(np.array(x), y, test_size = test_size,train_size= 0.75,random_state = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKhGTlqpqOAr"
   },
   "source": [
    "# Split the Dataset\n",
    "Time to split the dataset into training and testing sets! Let’s keep the test set 25% of everything and use the load_data function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a92bN5vAqRb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Dell/Desktop/set\\Actor_01\n",
      "C:/Users/Dell/Desktop/set\\Actor_02\n",
      "C:/Users/Dell/Desktop/set\\Actor_03\n",
      "C:/Users/Dell/Desktop/set\\Actor_04\n",
      "C:/Users/Dell/Desktop/set\\Actor_05\n",
      "C:/Users/Dell/Desktop/set\\Actor_06\n",
      "C:/Users/Dell/Desktop/set\\Actor_07\n",
      "C:/Users/Dell/Desktop/set\\Actor_08\n",
      "C:/Users/Dell/Desktop/set\\Actor_09\n",
      "C:/Users/Dell/Desktop/set\\Actor_10\n",
      "C:/Users/Dell/Desktop/set\\Actor_11\n",
      "C:/Users/Dell/Desktop/set\\Actor_12\n",
      "C:/Users/Dell/Desktop/set\\Actor_13\n",
      "C:/Users/Dell/Desktop/set\\Actor_14\n",
      "C:/Users/Dell/Desktop/set\\Actor_15\n",
      "C:/Users/Dell/Desktop/set\\Actor_16\n",
      "C:/Users/Dell/Desktop/set\\Actor_17\n",
      "C:/Users/Dell/Desktop/set\\Actor_18\n",
      "C:/Users/Dell/Desktop/set\\Actor_19\n",
      "C:/Users/Dell/Desktop/set\\Actor_20\n",
      "C:/Users/Dell/Desktop/set\\Actor_21\n",
      "C:/Users/Dell/Desktop/set\\Actor_22\n",
      "C:/Users/Dell/Desktop/set\\Actor_23\n",
      "C:/Users/Dell/Desktop/set\\Actor_24\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "import time\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46eeiQbYqT7p"
   },
   "source": [
    "#Observe the shape of the training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_MXFh4lwqYaC",
    "outputId": "eb020e32-a754-4510-97b1-8aaddfba58de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 583)\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmwRPZe7qey5"
   },
   "source": [
    "# Number of features extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "H3C6czeDqgxX",
    "outputId": "8625bb60-0a8b-4f66-9b50-88a536ea8b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEvGnx7r3W7f"
   },
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvggD94ZqmAY"
   },
   "outputs": [],
   "source": [
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cG4YLLXGqpAb"
   },
   "source": [
    "#Fit/train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "9OfJEVsDqrbY",
    "outputId": "b488b813-c7c9-475e-e527-9428af91ae5c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDC7AkAt21EF"
   },
   "source": [
    "# Predict the accuracy of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2Kzw2Emqt1p"
   },
   "source": [
    "Let’s predict the values for the test set. This gives us y_pred (the predicted emotions for the features in the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNVNDVnBqw1z"
   },
   "outputs": [],
   "source": [
    "# Predict for the test set\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njU6Gs6jqzkg"
   },
   "source": [
    "To calculate the accuracy of our model, we’ll call up the accuracy_score() function we imported from sklearn. Finally, we’ll round the accuracy to 2 decimal places and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_sDEv4K1q1VA",
    "outputId": "b701c4ab-54b0-4173-ebe5-da659c5dd44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.73%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGdh6fh02hFc"
   },
   "source": [
    "#classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "2xreI8SSq6Rc",
    "outputId": "e7a791de-bbc6-47d7-fdbe-ab80a0f8e53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.85      0.77      0.81        78\n",
      "        calm       0.77      0.81      0.79        89\n",
      "     disgust       0.65      0.62      0.64        45\n",
      "     fearful       0.61      0.80      0.69        87\n",
      "       happy       0.90      0.73      0.80        99\n",
      "     neutral       0.76      0.73      0.75        56\n",
      "         sad       0.74      0.52      0.61        89\n",
      "   surprised       0.55      0.88      0.67        40\n",
      "\n",
      "    accuracy                           0.73       583\n",
      "   macro avg       0.73      0.73      0.72       583\n",
      "weighted avg       0.75      0.73      0.73       583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZZZBmK32ksS"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "Y2IEjtiTtl-f",
    "outputId": "f5c2e30f-b101-4728-9547-f68b4774cbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60  1  3  7  0  1  1  5]\n",
      " [ 0 72  1  2  4  3  3  4]\n",
      " [ 1  1 28  8  0  1  1  5]\n",
      " [ 3  1  3 70  2  1  7  0]\n",
      " [ 5  4  3  5 72  1  3  6]\n",
      " [ 0  5  2  2  0 41  1  5]\n",
      " [ 2 10  2 19  1  5 46  4]\n",
      " [ 0  0  1  2  1  1  0 35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test,y_pred)\n",
    "print (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "text",
    "id": "EbipGM_Xnfyb"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    " \n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    " \n",
    "def plot_confusion_matrix(data, labels, output_filename):\n",
    "    \"\"\"Plot confusion matrix using heatmap.\n",
    " \n",
    "    Args:\n",
    "        data (list of list): List of lists with confusion matrix data.\n",
    "        labels (list): Labels which will be plotted across x and y axis.\n",
    "        output_filename (str): Path to output file.\n",
    " \n",
    "    \"\"\"\n",
    "    seaborn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(9, 6))\n",
    " \n",
    "    plt.title(\"Confusion Matrix\")\n",
    " \n",
    "    seaborn.set(font_scale=1.4)\n",
    "    ax = seaborn.heatmap(data, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    " \n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    " \n",
    "    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    " \n",
    "    plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    " \n",
    "# define data\n",
    "data =[[60,  1,  3,  7,  0,  1,  1,  5],\n",
    "       [ 0, 72,  1,  2,  4,  3,  3,  4],\n",
    "       [ 1,  1, 28,  8,  0,  1,  1,  5],\n",
    "       [ 3,  1,  3, 70,  2,  1,  7,  0],\n",
    "       [ 5,  4,  3,  5, 72,  1,  3,  6],\n",
    "       [ 0,  5,  2,  2,  0, 41,  1,  5],\n",
    "       [ 2, 10,  2, 19,  1,  5, 46,  4],\n",
    "       [ 0,  0,  1,  2,  1,  1,  0, 35]]\n",
    "\n",
    "# define labels\n",
    "labels = ['neutral','calm','happy','sad','angry','fearful', 'disgust','surprised']\n",
    " \n",
    "# create confusion matrix\n",
    "plot_confusion_matrix(data, labels, \"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing different model files to file\n",
    "with open( 'modelForPrediction5.sav', 'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinalSER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
